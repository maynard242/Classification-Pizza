{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# W207 Final Project\n",
    "Erika, Jen Jen, Geoff, Leslie\n",
    "\n",
    "(In Python 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As of 3/35\n",
    "\n",
    "Outline:\n",
    "\n",
    "* Data Pre-Processing  \n",
    "* Simple Feature Selection\n",
    "* Basline Models\n",
    "* Possible Approaches\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 1 Loading and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'vaderSentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4efe413caa7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvaderSentiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvaderSentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# General libraries.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'vaderSentiment'"
     ]
    }
   ],
   "source": [
    "## Import Libraries ##\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pandas import *\n",
    "from pandas.io.json import json_normalize\n",
    "from vaderSentiment import vaderSentiment\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get Data ##\n",
    "\n",
    "#reference on data: https://www.kaggle.com/c/random-acts-of-pizza/data\n",
    "# pull in the training and test data\n",
    "with open('/Users/gstirling/Desktop/W207_Proj/data/train.json', encoding='utf-8') as data_file:\n",
    "#with open('/home/levi/Documents/W207_Proj/data/train.json', encoding='utf-8') as data_file:\n",
    "    trainData = json.loads(data_file.read())   \n",
    "with open('//Users/gstirling/Desktop/W207_Proj/data/test.json', encoding='utf-8') as data_file:\n",
    "#with open('/home/levi/Documents/W207_Proj/data/train.json', encoding='utf-8') as data_file:\n",
    "    testData = json.loads(data_file.read())    \n",
    "\n",
    "# create a dev data set \n",
    "devData = trainData[0:1000]\n",
    "trainData = trainData[1000:]\n",
    "\n",
    "# show how the data looks in its original format\n",
    "#pprint(\"data in json format:\")\n",
    "#pprint(trainData[1])\n",
    "\n",
    "# create a normalized view\n",
    "allTData = json_normalize(trainData)\n",
    "print(\"\\nSize of the normalized Data:\", allTData.shape)\n",
    "print(\"\\nnormalized data columns:\", list(allTData))\n",
    "\n",
    "allDData = json_normalize(devData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.1 Text data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Create subsets of data for analysis ###\n",
    "\n",
    "# create a flat dataset without the subreddits list\n",
    "flatData = allTData.drop('requester_subreddits_at_request', 1)\n",
    "# create a separate dataset with just subreddits, indexed on request id\n",
    "# we can creata a count vector on the words, run Naive Bayes against it, \n",
    "# and add the probabilities to our flat dataset\n",
    "subredTData = allTData[['request_id','requester_subreddits_at_request']]\n",
    "subredTData.set_index('request_id', inplace=True)\n",
    "\n",
    "subredDData= allDData[['request_id','requester_subreddits_at_request']]\n",
    "subredDData.set_index('request_id', inplace=True)\n",
    "\n",
    "# our training labels\n",
    "trainLabel = allTData['requester_received_pizza']\n",
    "\n",
    "devLabel = allDData['requester_received_pizza']\n",
    "\n",
    "# what do these look like?\n",
    "#print(list(flatData))\n",
    "print(subredTData.shape)\n",
    "#print(subredTData['requester_subreddits_at_request'][1])\n",
    "\n",
    "# create a corpus of subreddits to vectorize\n",
    "trainCorpus = []\n",
    "for index in range(len(subredTData)):\n",
    "    trainCorpus.append(' '.join(subredTData['requester_subreddits_at_request'][index]))\n",
    "\n",
    "devCorpus = []\n",
    "for index in range(len(subredDData)):\n",
    "    devCorpus.append(' '.join(subredDData['requester_subreddits_at_request'][index]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine all text sources into a single corpus\n",
    "fldTText = allTData[['request_id','request_text', 'request_text_edit_aware', 'request_title']]\n",
    "fldDText = allDData[['request_id','request_text', 'request_text_edit_aware', 'request_title']]\n",
    "\n",
    "trainCorpus = []\n",
    "for index in range(len(subredTData)):\n",
    "    a = ' '.join(subredTData['requester_subreddits_at_request'][index])\n",
    "    b = (a, fldTText['request_text'][index], fldTText['request_text_edit_aware'][index],\n",
    "        fldTText['request_title'][index])\n",
    "    trainCorpus.append(' '.join(b))\n",
    "\n",
    "devCorpus = []\n",
    "for index in range(len(subredDData)):\n",
    "    a = ' '.join(subredDData['requester_subreddits_at_request'][index])\n",
    "    b = (a, fldDText['request_text'][index], fldDText['request_text_edit_aware'][index],\n",
    "         fldDText['request_title'][index])\n",
    "    devCorpus.append(' '.join(b))\n",
    "\n",
    "# Print 3 examples  \n",
    "print (trainCorpus[:3])\n",
    "labels = trainLabel.astype(int)\n",
    "labels = list(labels)\n",
    "print(labels[:3])\n",
    "print('-'*75)\n",
    "\n",
    "print ('\\n' , devCorpus[:3])\n",
    "labels_dev = devLabel.astype(int)\n",
    "labels_dev = list(labels_dev)\n",
    "print(labels_dev[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#posts = subredTData\n",
    "\n",
    "sentences2 = [\"Hello, thank you very much\", \"No, that's an awful idea\"]\n",
    "\n",
    "sentences.extend(sentences2)\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for post in sentences:\n",
    "    print(post)\n",
    "    ss = sid.polarity_scores(post)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}': {1}, '.format(k, ss[k]), end='')\n",
    "    print()\n",
    "    \n",
    "#for post in subredTData:\n",
    "#    print(post,\n",
    "#    sentiment = vaderSentiment(post))\n",
    "#    print(\"\\n\\t\" + str(sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.2 User status analysis (votes, flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CREATE SUBSETS FOR USER STATUS ANALYSIS ##\n",
    "\n",
    "# subsets for upvotes-downvotes and upvotes+downvotes at time of request and retrieval\n",
    "diffTrequest = allTData['requester_upvotes_minus_downvotes_at_request']\n",
    "diffDrequest = allDData['requester_upvotes_minus_downvotes_at_request']\n",
    "diffTretrieval = allTData['requester_upvotes_minus_downvotes_at_retrieval']\n",
    "diffDretrieval = allDData['requester_upvotes_minus_downvotes_at_retrieval']\n",
    "totalvotesTrequest = allTData['requester_upvotes_plus_downvotes_at_request']\n",
    "totalvotesDrequest = allDData['requester_upvotes_plus_downvotes_at_request']\n",
    "totalvotesTretrieval = allTData['requester_upvotes_plus_downvotes_at_retrieval']\n",
    "totalvotesDretrieval = allDData['requester_upvotes_plus_downvotes_at_retrieval']\n",
    "\n",
    "# subsets for flair (training data only)\n",
    "Tflair = allTData['requester_user_flair'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "## CREATING NEW PARAMETER: the change in upvotes-downvotes from time of request to time of retrieval ##\n",
    "\n",
    "# user status with new parameter for training data\n",
    "allTData['request_to_retrieval_upvotes_minus_downvotes'] = diffTretrieval - diffTrequest\n",
    "diffTcombined = allTData[['requester_upvotes_minus_downvotes_at_request','requester_upvotes_minus_downvotes_at_retrieval',\n",
    "                          'request_to_retrieval_upvotes_minus_downvotes','requester_received_pizza']].copy()\n",
    "# rename column headings\n",
    "diffTcombined.columns = ['Request', 'Retrieval', 'Request-Retrieval', 'Got Pizza']\n",
    "# print(\"ADDING NEW PARAMETER - REQUEST-RETRIEVAL:  to represent change in counts from upvotes-downvotes from time of request to time of retrieval.\")\n",
    "# print(\"\\nSTATUS TRAINING DATA\")\n",
    "# display(diffTcombined.head())\n",
    "\n",
    "# user status with new parameter for training data\n",
    "allDData['request_to_retrieval_upvotes_minus_downvotes'] = diffDretrieval - diffDrequest\n",
    "diffDcombined = allDData[['requester_upvotes_minus_downvotes_at_request','requester_upvotes_minus_downvotes_at_retrieval',\n",
    "                          'request_to_retrieval_upvotes_minus_downvotes','requester_received_pizza']].copy()\n",
    "# rename columne headings\n",
    "diffDcombined.columns = ['Request', 'Retrieval', 'Request-Retrieval', 'Got Pizza']\n",
    "# print(\"\\n\")\n",
    "# print(\"STATUS DEVELOPMENT DATA\")\n",
    "# display(diffDcombined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## SUMMARY STATISTICS FOR UPVOTES-DOWNVOTES AT REQUEST AND AT RETRIEVAL ##\n",
    "\n",
    "# upvotes-downvotes at request, grouped by pizza success -------------------------\n",
    "# print(\"\\n\\nSUMMARY STATISTICS FOR UPVOTES-DOWNVOTES AT REQUEST AND AT RETRIEVAL, GROUPED BY PIZZA SUCCESS\")\n",
    "\n",
    "diffreq_pizzas = allTData[['requester_upvotes_minus_downvotes_at_request','requester_received_pizza']].copy()\n",
    "diffreq_pizzas.columns = ['Request', 'Got Pizza']\n",
    "pizza_diff_request = diffreq_pizzas.groupby(['Got Pizza'])\n",
    "# print(\"\\nGroup upvotes-downvotes at request by pizza success:\\n\")\n",
    "# print(round(pizza_diff_request.describe(), 2))\n",
    "\n",
    "# upvotes-downvotes at retrieval, grouped by pizza success -------------------------\n",
    "diffretrieve_pizzas = allTData[['requester_upvotes_minus_downvotes_at_retrieval','requester_received_pizza']].copy()\n",
    "diffretrieve_pizzas.columns = ['Retrieval', 'Got Pizza']\n",
    "pizza_diff_retrieval = diffretrieve_pizzas.groupby(['Got Pizza'])\n",
    "# print(\"\\n\")\n",
    "# print(\"-\"*100)\n",
    "# print(\"\\nGroup upvotes-downvotes at retrieval by pizza success:\\n\")\n",
    "# print(round(pizza_diff_retrieval.describe(), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## USER FLAIR ##\n",
    "# None = no pizza\n",
    "#'shroom' = got pizza without 'pay it forward' (PIF)\n",
    "# PIF' = got pizza and paid forward\n",
    "\n",
    "flair = allTData[['requester_user_flair','requester_received_pizza']].copy()\n",
    "flair.columns = ['Flair', 'Got Pizza']\n",
    "# print(\"\\n\")\n",
    "# print(\"Types of Flair and Pizza Success\\n\")\n",
    "# print(flair.head(10))\n",
    "pizza_flair = flair.groupby(['Got Pizza'])\n",
    "# print(\"\\n\")\n",
    "# print(\"-\"*100)\n",
    "# print(\"\\nGroup flair by pizza success:\\n\")\n",
    "# print(round(pizza_flair.describe(),2))\n",
    "\n",
    "# binarize categorical features in FLAIR\n",
    "bin_flair = flair['Flair'].replace(['None', 'shroom', 'PIF'], [-1, 0, 1])\n",
    "bin_flair.value_counts()\n",
    "# print(\"\\nOut of 734 pizza recipients, 683 did not PIF and 51 did PIF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CONVERT UPVOTES-DOWNVOTES SUBSETS INTO Z-SCORES FOR STANDARDIZATION ##\n",
    "## CREATE FINAL SUBSET FOR UPVOTES-DOWNVOTES, Z-SCORES, AND FLAIR ##\n",
    "\n",
    "# Z-scores for training data\n",
    "statusTtrain = allTData[['requester_upvotes_minus_downvotes_at_request','requester_upvotes_minus_downvotes_at_retrieval',\n",
    "                          'request_to_retrieval_upvotes_minus_downvotes']].copy()\n",
    "statusTtrain.columns = ['Request', 'Retrieval', 'Request-Retrieval']\n",
    "for col in statusTtrain:\n",
    "    zscore_col = col + \" Z-score\"\n",
    "    statusTtrain[zscore_col] = (statusTtrain[col] - statusTtrain[col].mean() / statusTtrain[col].std(ddof=0))\n",
    "statusTtrain = (statusTtrain).join(allTData['requester_user_flair'])\n",
    "# display(statusTtrain.head())\n",
    "\n",
    "# Z-scores for development data\n",
    "statusDtrain = allDData[['requester_upvotes_minus_downvotes_at_request','requester_upvotes_minus_downvotes_at_retrieval',\n",
    "                          'request_to_retrieval_upvotes_minus_downvotes']].copy()\n",
    "statusDtrain.columns = ['Request', 'Retrieval', 'Request-Retrieval']\n",
    "\n",
    "for col in statusDtrain:\n",
    "    zscore_dev_col = col + \" Z-score\"\n",
    "    statusDtrain[zscore_dev_col] = (statusDtrain[col] - statusDtrain[col].mean() / statusDtrain[col].std(ddof=0))\n",
    "statusDtrain = (statusDtrain).join(allDData['requester_user_flair'])\n",
    "# display(statusDtrain.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.3 Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from IPython.display import display\n",
    "\n",
    "# CHANGE UNIX TO DATETIME\n",
    "unix = allTData[['unix_timestamp_of_request_utc', 'requester_received_pizza']].copy()\n",
    "\n",
    "# unix --> datetime\n",
    "unix['Datetime'] = pandas.to_datetime(unix['unix_timestamp_of_request_utc'], unit='s')\n",
    "# just in case we wanted to add date columns to original dataframe\n",
    "unix['Date'] = unix['Datetime'].dt.date\n",
    "unix['Hour'] = unix['Datetime'].dt.hour\n",
    "print(\"Converted unix timestamp to Date and Time:\")\n",
    "# display(unix.head(5))\n",
    "\n",
    "# set datetime as index\n",
    "unix_index = unix.set_index('Datetime')\n",
    "unix_index = unix_index.drop(['unix_timestamp_of_request_utc', 'Date'], axis=1)\n",
    "print(\"\\nIndexed by Date and time:\")\n",
    "# display(unix_index.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trial grouping by different dates or seasons\n",
    "\n",
    "# find Christmas\n",
    "# index by 1 date\n",
    "christmas2012_pizza = unix_index['2012-12-25']\n",
    "print(\"To index by 1 date\")\n",
    "# display(christmas2012_pizza)\n",
    "\n",
    "# to index by specific month and day\n",
    "# christmas_pizza = unix_index[unix_index.Date.dt.]\n",
    "\n",
    "# index a season, ex: summer\n",
    "summer_pizza = unix_index['2013-05-01':'2013-08-31']\n",
    "print(\"\\nSummer pizzas:\")\n",
    "# display(summer_pizza.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# plot pizzas by month \n",
    "unix_index_base = unix_index.drop(['Hour'], axis=1)\n",
    "month_pizzas = unix_index_base.resample('M').sum()\n",
    "month_pizzas_area = month_pizzas.plot(kind='area')\n",
    "\n",
    "\n",
    "month_pizzas_bar = month_pizzas.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analyze pattern by days/weeks\n",
    "\n",
    "# Take a look at the highest frequency months (07/31/2012 and 4/30/2013)\n",
    "July2012 = unix_index['7/2012'].resample('D').mean()\n",
    "# July2012_area = July2012.plot(kind='area')\n",
    "\n",
    "April2013 = unix_index['4/2013'].resample('W').mean()\n",
    "April2013_area = April2013.plot(kind='area')\n",
    "\n",
    "\n",
    "# Take a look at the lowest frequency months\n",
    "Nov2012 = unix_index['11/2012'].resample('D').mean()\n",
    "# Nov2012_area = Nov2012.plot(kind='area')\n",
    "\n",
    "Jun2013 = unix_index['6/2013'].resample('W').mean()\n",
    "Jun2013_area = Jun2013.plot(kind='area')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analyze pattern by hours\n",
    "\n",
    "hourly = unix_index['10/2012':'9/2013'].groupby('Hour')['requester_received_pizza'].sum()\n",
    "print(hourly.describe())\n",
    "print(hourly)\n",
    "print(\"Pizza success by hour of the day\")\n",
    "hourly.plot('area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 2. Simple Feature Selection and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Simple Pre-Processing\n",
    "\n",
    "def data_preprocessor(s):\n",
    "    \"\"\"\n",
    "    Note: this function pre-processors data:\n",
    "    (1) removes non-alpha characters\n",
    "    (2) converts digits to 'number'\n",
    "    (3) regularizes spaces (although CountVectorizer ignores this unless they are part of words)\n",
    "    (4) reduces word size to n\n",
    "    \"\"\"\n",
    "\n",
    "    s = [re.sub(r'[?|$|.|!|@|\\n|(|)|<|>|_|-|,|\\']',r' ',s) for s in s] # strip out non-alpha numeric char, replace with space\n",
    "    s = [re.sub(r'\\d+',r'number ',s) for s in s] # convert digits to number\n",
    "    s = [re.sub(r' +',r' ',s) for s in s] # convert multiple spaces to single space\n",
    "    \n",
    "    # This sets word size to n=5\n",
    "    num = 5\n",
    "    def set_word(s):\n",
    "        temp = []\n",
    "        for s in s:\n",
    "            x = s.split()\n",
    "            z = [elem[:num] for elem in x]\n",
    "            z = ' '.join(z)\n",
    "            temp.append(z)       \n",
    "        return temp\n",
    "    \n",
    "    s = set_word(s)\n",
    "    \n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set up the data with CountVectorizer\n",
    "\n",
    "#vectorizer = CountVectorizer(lowercase=True, strip_accents='unicode',stop_words='english')\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1,lowercase=True)\n",
    "tVector = vectorizer.fit_transform(trainCorpus)\n",
    "dVector = vectorizer.transform(devCorpus)\n",
    "\n",
    "print ('\\nRaw data:')\n",
    "print (\"The size of the vocabulary for the training text data is\", tVector.shape[1])\n",
    "print (\"First 5 feature Names:\", vectorizer.get_feature_names()[1:6], \"\\n\")\n",
    "\n",
    "tVector_p = vectorizer.fit_transform(data_preprocessor(trainCorpus))\n",
    "dVector_p = vectorizer.transform(data_preprocessor(devCorpus))\n",
    "\n",
    "print ('\\nPre-Processed data:')\n",
    "print (\"The size of the vocabulary for the training text data is\", tVector_p.shape[1])\n",
    "print (\"First 5 feature Names:\", vectorizer.get_feature_names()[1:6], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 3. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group scoring functions\n",
    "\n",
    "def roc_curve1(y_true, y_pred_prob):\n",
    "    \"\"\"This function plots the ROC curve\n",
    "    Inputs: y_true, correct label\n",
    "            y_pred_prob, predicted probabilities\n",
    "    \"\"\"\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_pred_prob)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def score_rep(y_true, y_pred, desc):\n",
    "    \"\"\"Function to print out comprehensive report for classification test\n",
    "    Inputs: y_true, correct label\n",
    "            y_pred, predicted label from model\n",
    "            desc, description of model\n",
    "    Output: classification report\n",
    "    \"\"\"\n",
    "    print(desc)\n",
    "    print(\"-\"*75)\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(y_true, y_pred))\n",
    "    print(\"Area under curve of ROC: \", metrics.roc_auc_score(y_true, y_pred))\n",
    "    print(\"Classification report:\\n\")\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print(\"-\"*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Subreddit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.1a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "C = 0.01 #(For now)\n",
    "\n",
    "modelLogit = LogisticRegression(penalty='l2', C=C)\n",
    "modelLogit.fit(tVector,trainLabel)\n",
    "logitScore = round(modelLogit.score(dVector, devLabel), 4)\n",
    "print(\"For C = \", C, \"Logistic regression accuracy:\", logitScore)\n",
    "\n",
    "modelLogit.fit(tVector_p,trainLabel)\n",
    "logitScore = round(modelLogit.score(dVector_p, devLabel), 4)\n",
    "print(\"For C = \", C, \"Logistic regression (processed data) accuracy:\", logitScore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.1b Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Multinomial NB\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "clf = BernoulliNB(alpha=alpha)\n",
    "clf.fit(tVector, trainLabel)\n",
    "test_predicted_labels = clf.predict(dVector) \n",
    "print ('Bernoulli NB using raw data with alpha = %1.3f:' %alpha, metrics.accuracy_score(devLabel,test_predicted_labels) )\n",
    "\n",
    "clf.fit(tVector_p, trainLabel)\n",
    "test_predicted_labels = clf.predict(dVector_p) \n",
    "print ('Bernoulli NB using processed data  with alpha = %1.3f:' %alpha, metrics.accuracy_score(devLabel,test_predicted_labels) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.1c Logistic Regression More Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the best regularization\n",
    "regStrength = [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 6.0, 10.0]\n",
    "\n",
    "\n",
    "for c in regStrength:\n",
    "    modelLogit = LogisticRegression(penalty='l1', C=c)\n",
    "    modelLogit.fit(tVector_p, trainLabel)\n",
    "    logitScore = round(modelLogit.score(dVector_p, devLabel), 4)\n",
    "    print(\"For C = \", c, \"Logistic regression accuracy:\", logitScore)\n",
    "\n",
    "# although the best score comes from c=.001, the bet F1-score \n",
    "# comes from c=.5, and this gives better weight options\n",
    "modelLogit = LogisticRegression(penalty='l1', C=.5, tol = .1)\n",
    "modelLogit.fit(tVector_p, trainLabel)\n",
    "\n",
    "print(max(modelLogit.coef_[0]))\n",
    "numWeights = 5\n",
    "\n",
    "sortIndex = np.argsort(modelLogit.coef_)\n",
    "iLen = len(sortIndex[0])\n",
    "print(\"\\nTop\", numWeights, \"Weighted Features:\")\n",
    "\n",
    "for index in range((iLen - numWeights) , iLen):\n",
    "    lookup = sortIndex[0][index]\n",
    "    print(lookup)\n",
    "    weight =  modelLogit.coef_[0][lookup]\n",
    "    print(vectorizer.get_feature_names()[sortIndex[0][index]], weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 LR models for Status/Time features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2a LR model for Status Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION MODELS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "# create training labels for pizza success\n",
    "train_labels = np.asarray(allTData['requester_received_pizza'])\n",
    "dev_labels = np.asarray(allDData['requester_received_pizza'])\n",
    "\n",
    "# Z-scored for Request-Retrieval Z-score\n",
    "diff_combined = np.asarray(statusTtrain[['Request-Retrieval Z-score']].copy())\n",
    "diff_dev_combined = np.asarray(statusDtrain[['Request-Retrieval Z-score']].copy())\n",
    "train_combine_model = lr.fit(diff_combined, train_labels)\n",
    "dev_combine_labels = train_combine_model.predict(diff_dev_combined)\n",
    "combine_score = train_combine_model.score(diff_dev_combined, dev_labels)\n",
    "combine_F1score = metrics.f1_score(dev_combine_labels, dev_labels)\n",
    "\n",
    "# Z-scores for Request, Retrieval, and Request-Retrieval Z-scores and Flair\n",
    "zcomb_train = statusTtrain[['Request Z-score','Retrieval Z-score','Request-Retrieval Z-score', 'requester_user_flair']]\n",
    "zcomb_train['requester_user_flair'] = zcomb_train['requester_user_flair'].apply(flair_numeric).fillna(0)\n",
    "\n",
    "zcomb_dev = statusDtrain[['Request Z-score','Retrieval Z-score','Request-Retrieval Z-score', 'requester_user_flair']]\n",
    "zcomb_dev['requester_user_flair'] = zcomb_dev['requester_user_flair'].apply(flair_numeric).fillna(0)\n",
    "\n",
    "zcomb_model = lr.fit(zcomb_train, train_labels)\n",
    "zcomb_labels = zcomb_model.predict(zcomb_dev)\n",
    "zcomb_score = zcomb_model.score(zcomb_dev, dev_labels)\n",
    "zcomb_F1score = metrics.f1_score(zcomb_labels, dev_labels)\n",
    "\n",
    "# Z-scores for Request, Retrieval, and Request-Retrieval Z-scores\n",
    "z_status_train = statusTtrain[['Request Z-score','Retrieval Z-score','Request-Retrieval Z-score']]\n",
    "z_status_dev = statusDtrain[['Request Z-score','Retrieval Z-score','Request-Retrieval Z-score']]\n",
    "\n",
    "z_status_model = lr.fit(z_status_train, train_labels)\n",
    "z_status_labels = z_status_model.predict(z_status_dev)\n",
    "z_status_score = z_status_model.score(z_status_dev, dev_labels)\n",
    "z_status_F1score = metrics.f1_score(z_status_labels, dev_labels)\n",
    "\n",
    "                       \n",
    "print(\"\\nFor model with Request-Retrieval Z-Score only:\")\n",
    "print(\"Accuracy:\", combine_score)\n",
    "print(\"F1 score:\", combine_F1score)\n",
    "\n",
    "print(\"\\nZ-scores for Request, Retrieval, Request-Retrieval Z-Score and Flair:\")\n",
    "print(\"Accuracy:\", zcomb_score)\n",
    "print(\"F1 score:\", zcomb_F1score)\n",
    "                        \n",
    "print(\"\\nZ-scores for Request, Retrieval, Request-Retrieval Z-Score:\")\n",
    "print(\"Accuracy:\", z_status_score)\n",
    "print(\"F1 score:\", z_status_F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2b LR model for Status + Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR STATUS AND TIME BY HOUR\n",
    "lr = LogisticRegression(penalty='l2', C=0.01)\n",
    "\n",
    "train_labels = np.asarray(allTData['requester_received_pizza'])\n",
    "dev_labels = np.asarray(allDData['requester_received_pizza'])\n",
    "\n",
    "# setup training and development datasets\n",
    "# train\n",
    "stathourTData = pandas.concat([statusTtrain['Request-Retrieval Z-score'], allTData['unix_timestamp_of_request_utc']], axis=1, \n",
    "                              keys=['Request-Retrieval Z-score', 'unix_timestamp_of_request_utc'])\n",
    "stathourTData['Datetime'] = pandas.to_datetime(stathourTData['unix_timestamp_of_request_utc'], unit='s')\n",
    "stathourTData['Hour'] = stathourTData['Datetime'].dt.hour\n",
    "stathourTData = stathourTData.drop(['Datetime', 'unix_timestamp_of_request_utc'], axis=1)\n",
    "# display(stathourTData.head(5))\n",
    "\n",
    "# development\n",
    "stathourDData = pandas.concat([statusDtrain['Request-Retrieval Z-score'], allDData['unix_timestamp_of_request_utc']], axis=1, \n",
    "                              keys=['Request-Retrieval Z-score', 'unix_timestamp_of_request_utc'])\n",
    "stathourDData['Datetime'] = pandas.to_datetime(stathourDData['unix_timestamp_of_request_utc'], unit='s')\n",
    "stathourDData['Hour'] = stathourDData['Datetime'].dt.hour\n",
    "stathourDData = stathourDData.drop(['Datetime', 'unix_timestamp_of_request_utc'], axis=1)\n",
    "# display(stathourDData.head(5))\n",
    "\n",
    "# fit LR models\n",
    "train_stathour_model = lr.fit(stathourTData, train_labels)\n",
    "dev_stathour_labels = train_stathour_model.predict(stathourDData)\n",
    "stathour_score = train_stathour_model.score(stathourDData, dev_labels)\n",
    "stathour_F1score = metrics.f1_score(dev_stathour_labels, dev_labels)\n",
    "\n",
    "print(\"\\nScoring for Request-retrieval Z-scores and Hour\")\n",
    "print(\"Accuracy:\", stathour_score)\n",
    "print(\"F1 score:\", stathour_F1score)\n",
    "roc_curve1(dev_labels, train_stathour_model.predict_proba(stathourDData)[:,0])\n",
    "score_rep(dev_labels, dev_stathour_labels,\"Logistic Regression, C = 0.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2c LR model for Status and Bucketed Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR STATUS AND BUCKETED HOUR\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "# Bucket hours\n",
    "def bucket(x):\n",
    "    if x >= 6 and x <= 13:\n",
    "        return 0\n",
    "    if x >= 0 and x <=2:\n",
    "        return 1\n",
    "    if x >= 16 and x <=23:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "bucketTData = stathourTData\n",
    "bucketTData['Hour'] = bucketTData['Hour'].apply(bucket)\n",
    "bucketDData = stathourDData\n",
    "bucketDData['Hour'] = bucketDData['Hour'].apply(bucket)\n",
    "\n",
    "# fit LR models\n",
    "train_buckethr_model = lr.fit(bucketTData, train_labels)\n",
    "dev_buckethr_labels = train_buckethr_model.predict(bucketDData)\n",
    "buckethr_score = train_buckethr_model.score(bucketDData, dev_labels)\n",
    "buckethr_F1score = metrics.f1_score(dev_buckethr_labels, dev_labels)\n",
    "\n",
    "print(\"\\nScoring for Request-retrieval Z-scores and bucketed Hour:\")\n",
    "print(\"Accuracy:\", buckethr_score)\n",
    "print(\"F1 score:\", buckethr_F1score)\n",
    "roc_curve1(dev_labels, train_buckethr_model.predict_proba(bucketDData)[:,0])\n",
    "score_rep(dev_labels, dev_buckethr_labels,\"Logistic Regression, C = 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing our Vader\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "test = \"It was one of the worst movies I've seen, despite good reviews.\"\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(snt)))\n",
    "    print(snt['compound'])\n",
    "\n",
    "print_sentiment_scores(\"It was one of the worst movies I've seen, despite good reviews.\")\n",
    "\n",
    "#sentences = \"VADER is smart, handsome, and funny.\"\n",
    "\n",
    "#print_sentiment_scores(sentences)\n",
    "\n",
    "sentences = [\"VADER is smart, handsome, and funny.\", \"VADER is silly, ugly, and rude!\"]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"\\n\")\n",
    "    print(sentence)\n",
    "    vs = print_sentiment_scores(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up for Titles\n",
    "title = allTData[['request_title', 'requester_received_pizza']].copy()\n",
    "title.columns = ['Title', 'Got Pizza']\n",
    "print(\"\\n\")\n",
    "print(\"Titles and Pizza Success\\n\")\n",
    "print(title.head(10))\n",
    "pizza_title = title.groupby(['Got Pizza'])\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles = allTData['request_title']\n",
    "\n",
    "for title in titles:\n",
    "    print(\"\\n\")\n",
    "    print_sentiment_scores(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I think I have the wrong approach here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def score_rep(y_true, y_pred, desc):\n",
    "    \"\"\"Function to print out comprehensive report for classification test\n",
    "    Inputs: y_true, correct label\n",
    "            y_pred, predicted label from model\n",
    "            desc, description of model\n",
    "    Output: classification report\n",
    "    \"\"\"\n",
    "    print(desc)\n",
    "    print(\"-\"*75)\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(y_true, y_pred))\n",
    "    print(\"Area under curve of ROC: \", metrics.roc_auc_score(y_true, y_pred))\n",
    "    print(\"Classification report:\\n\")\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print(\"-\"*75)\n",
    "    \n",
    "C = 100\n",
    "\n",
    "modelLogit = LogisticRegression(penalty = 'l2', C = C)\n",
    "\n",
    "trainLabel = allTData['requester_received_pizza']\n",
    "\n",
    "devLabel = allDData['requester_received_pizza']\n",
    "\n",
    "snt = analyser.polarity_scores(sentence)\n",
    "\n",
    "title = snt['compound']\n",
    "\n",
    "modelLogit.fit(tVector,trainLabel)\n",
    "score_rep(devLabel,modelLogit.predict(dVector),'Logistic Regression, C = 0.001')\n",
    "\n",
    "modelLogit.fit(got_pizza,trainLabel)\n",
    "score_rep(devLabel,modelLogit.predict(dVector_p),'Logistic Regression, C = 0.001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up for Body Copy\n",
    "title = allTData[['request_text', 'requester_received_pizza']].copy()\n",
    "title.columns = ['Text', 'Got Pizza']\n",
    "print(\"\\n\")\n",
    "print(\"Text and Pizza Success\\n\")\n",
    "print(title.head(10))\n",
    "pizza_title = title.groupby(['Got Pizza'])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = allTData['request_text']\n",
    "\n",
    "for copy in text:\n",
    "    print(\"\\n\")\n",
    "    print_sentiment_scores(copy)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
