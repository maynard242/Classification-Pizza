{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is this file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is a storehouse for our work that did not make it into our final submitted model. We approached the Random Acts of Pizza challenge from many angles and you'll find several of those approaches below. We hope it will provide additional context around how we thought through the challenge and some of the things we learned through this process.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries ##\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pandas import *\n",
    "from pandas.io.json import json_normalize\n",
    "from vaderSentiment import vaderSentiment\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlxtend\n",
    "import scipy\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# SK-learn libraries for pre/processing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# Miscellaneous libraries\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of the normalized Data: (3040, 32)\n",
      "\n",
      "normalized data columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n"
     ]
    }
   ],
   "source": [
    "## Get Data ##\n",
    "\n",
    "# Reference for data: https://www.kaggle.com/c/random-acts-of-pizza/data\n",
    "# Pull in the training and test data\n",
    "with open('data/train.json', encoding='utf-8') as data_file:\n",
    "    trainData = json.loads(data_file.read())   \n",
    "\n",
    "with open('data/test.json', encoding='utf-8') as data_file:\n",
    "    testData = json.loads(data_file.read())    \n",
    "\n",
    "# create a dev data set \n",
    "devData = trainData[0:1000]\n",
    "trainData = trainData[1000:]\n",
    "\n",
    "# show how the data looks in its original format\n",
    "#pprint(\"data in json format:\")\n",
    "#pprint(trainData[1])\n",
    "\n",
    "# create a normalized view\n",
    "allTData = json_normalize(trainData)\n",
    "print(\"\\nSize of the normalized Data:\", allTData.shape)\n",
    "print(\"\\nnormalized data columns:\", list(allTData))\n",
    "\n",
    "allDData = json_normalize(devData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Setting Up & Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Libraries ##\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pandas import *\n",
    "from pandas.io.json import json_normalize\n",
    "from vaderSentiment import vaderSentiment\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful functions for analysis\n",
    "def roc_curve1(y_true, y_pred_prob):\n",
    "    \"\"\"This function plots the ROC curve\n",
    "    Inputs: y_true, correct label\n",
    "            y_pred_prob, predicted probabilities\n",
    "    \"\"\"\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_pred_prob)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def score_rep(y_true, y_pred, desc):\n",
    "    \"\"\"Function to print out comprehensive report for classification test\n",
    "    Inputs: y_true, correct label\n",
    "            y_pred, predicted label from model\n",
    "            desc, description of model\n",
    "    Output: classification report\n",
    "    \"\"\"\n",
    "    print(desc)\n",
    "    print(\"-\"*75)\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(y_true, y_pred))\n",
    "    print(\"Area under curve of ROC: \", metrics.roc_auc_score(y_true, y_pred))\n",
    "    print(\"Classification report:\\n\")\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print(\"-\"*75)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vaderSentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was one of the worst movies I've seen, despite good reviews. {'neg': 0.394, 'neu': 0.606, 'pos': 0.0, 'compound': -0.7584}\n",
      "-0.7584\n",
      "\n",
      "\n",
      "VADER is smart, handsome, and funny.\n",
      "VADER is smart, handsome, and funny.---- {'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n",
      "0.8316\n",
      "\n",
      "\n",
      "VADER is silly, ugly, and rude!\n",
      "VADER is silly, ugly, and rude!--------- {'neg': 0.617, 'neu': 0.281, 'pos': 0.103, 'compound': -0.7574}\n",
      "-0.7574\n"
     ]
    }
   ],
   "source": [
    "# Quick learning exercise to figure out how\n",
    "# to get vaderSentiment to work\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "test = \"It was one of the worst movies I've seen, despite good reviews.\"\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(snt)))\n",
    "    print(snt['compound'])\n",
    "\n",
    "print_sentiment_scores(\"It was one of the worst movies I've seen, despite good reviews.\")\n",
    "\n",
    "#sentences = \"VADER is smart, handsome, and funny.\"\n",
    "\n",
    "#print_sentiment_scores(sentences)\n",
    "\n",
    "sentences = [\"VADER is smart, handsome, and funny.\", \"VADER is silly, ugly, and rude!\"]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"\\n\")\n",
    "    print(sentence)\n",
    "    vs = print_sentiment_scores(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Titles and Pizza Success\n",
      "\n",
      "                                               Title Got Pizza\n",
      "0  [Request] Just got dumped, no food in the free...     False\n",
      "1  [Request]  Saint Augustine, US.  Boyfriend and...     False\n",
      "2        [Request] I'd love a Buffalo Chicken Puzza!      True\n",
      "3  [REQUEST]- I start class next week and i am st...     False\n",
      "4        [Request] Pizza for finals in Northern Iowa      True\n",
      "5      [request]lovepark,il. Preggers and very sad..     False\n",
      "6  [Request] My friend is letting me stay with hi...     False\n",
      "7  [Request] Painting our apartment today, would ...     False\n",
      "8  [REQUEST] Pennsylvania, USA living off PB&amp;...     False\n",
      "9          [Request] UK - Broke Student Exam Special      True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting up for Titles\n",
    "\n",
    "title = allTData[['request_title', 'requester_received_pizza']].copy()\n",
    "title.columns = ['Title', 'Got Pizza']\n",
    "print(\"\\n\")\n",
    "print(\"Titles and Pizza Success\\n\")\n",
    "print(title.head(10))\n",
    "pizza_title = title.groupby(['Got Pizza'])\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     requester_received_pizza  Vader Scores\n",
      "0                       False       -0.5994\n",
      "1                       False        0.2263\n",
      "2                        True        0.6696\n",
      "3                       False        0.2960\n",
      "4                        True        0.0000\n",
      "5                       False        0.0000\n",
      "6                       False        0.4588\n",
      "7                       False        0.6369\n",
      "8                       False        0.0000\n",
      "9                        True       -0.0258\n",
      "10                      False        0.5106\n",
      "11                      False       -0.3400\n",
      "12                      False       -0.7650\n",
      "13                      False        0.0000\n",
      "14                      False        0.0000\n",
      "15                      False       -0.4926\n",
      "16                       True        0.0000\n",
      "17                      False        0.5562\n",
      "18                      False       -0.4998\n",
      "19                      False        0.5859\n",
      "20                       True        0.6757\n",
      "21                      False       -0.4767\n",
      "22                       True        0.8911\n",
      "23                      False        0.0000\n",
      "24                      False        0.0000\n",
      "25                      False        0.4574\n",
      "26                      False        0.5707\n",
      "27                      False       -0.4215\n",
      "28                      False        0.4939\n",
      "29                       True        0.4767\n",
      "...                       ...           ...\n",
      "3010                    False       -0.1280\n",
      "3011                    False        0.3382\n",
      "3012                     True       -0.2263\n",
      "3013                    False       -0.1779\n",
      "3014                    False        0.8074\n",
      "3015                    False       -0.7178\n",
      "3016                    False        0.7096\n",
      "3017                    False        0.0000\n",
      "3018                    False        0.0745\n",
      "3019                    False       -0.8462\n",
      "3020                    False       -0.5106\n",
      "3021                    False       -0.4215\n",
      "3022                    False        0.5719\n",
      "3023                    False       -0.8020\n",
      "3024                     True       -0.5106\n",
      "3025                    False        0.7845\n",
      "3026                    False       -0.4215\n",
      "3027                    False        0.0387\n",
      "3028                    False       -0.4215\n",
      "3029                    False       -0.1280\n",
      "3030                    False        0.5106\n",
      "3031                    False        0.8360\n",
      "3032                    False        0.4199\n",
      "3033                    False        0.0000\n",
      "3034                    False        0.0000\n",
      "3035                    False        0.4019\n",
      "3036                     True        0.8779\n",
      "3037                    False        0.6696\n",
      "3038                    False        0.4939\n",
      "3039                    False        0.0000\n",
      "\n",
      "[3040 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles = allTData['request_title']\n",
    "\n",
    "    \n",
    "df = pd.DataFrame(data = allTData)\n",
    "\n",
    "df = df[['request_title', 'requester_received_pizza']]\n",
    "\n",
    "\n",
    "titles = allTData['request_title']\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = analyser.polarity_scores(sentence)\n",
    "    snt['compund']\n",
    "    #print(\"{:-<40} {}\".format(sentence, str(snt)))\n",
    "    #print(snt['compound'])\n",
    "    \n",
    "scores = []\n",
    "\n",
    "for title in titles:\n",
    "    scores.append(analyser.polarity_scores(title)['compound'])\n",
    "\n",
    "#print(scores[1:10])\n",
    "\n",
    "df[\"Vader Scores\"] = scores\n",
    "\n",
    "#df.head(10)\n",
    "\n",
    "df = df.drop('request_title', axis = 1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    requester_received_pizza  Vader Scores\n",
      "0                      False        0.6124\n",
      "1                      False       -0.2960\n",
      "2                      False        0.6696\n",
      "3                      False        0.0000\n",
      "4                      False        0.8455\n",
      "5                       True        0.0000\n",
      "6                      False        0.4019\n",
      "7                      False        0.0000\n",
      "8                      False       -0.3862\n",
      "9                       True        0.0000\n",
      "10                      True        0.4939\n",
      "11                     False        0.6369\n",
      "12                     False        0.7430\n",
      "13                     False       -0.4215\n",
      "14                     False        0.0000\n",
      "15                     False        0.0000\n",
      "16                      True       -0.0772\n",
      "17                     False       -0.4215\n",
      "18                      True        0.1280\n",
      "19                     False       -0.2500\n",
      "20                     False        0.7959\n",
      "21                     False       -0.7269\n",
      "22                     False        0.0000\n",
      "23                     False        0.0000\n",
      "24                      True        0.0000\n",
      "25                     False       -0.0772\n",
      "26                     False       -0.5106\n",
      "27                     False        0.0000\n",
      "28                     False        0.0000\n",
      "29                     False        0.0000\n",
      "..                       ...           ...\n",
      "970                     True        0.4019\n",
      "971                    False       -0.0772\n",
      "972                    False        0.0000\n",
      "973                    False        0.0000\n",
      "974                    False        0.4389\n",
      "975                    False        0.2960\n",
      "976                    False       -0.4767\n",
      "977                    False       -0.3818\n",
      "978                    False        0.0000\n",
      "979                     True        0.3182\n",
      "980                     True        0.0000\n",
      "981                    False        0.0000\n",
      "982                     True        0.0000\n",
      "983                     True       -0.5423\n",
      "984                    False        0.3412\n",
      "985                     True        0.6249\n",
      "986                    False        0.0000\n",
      "987                    False        0.5499\n",
      "988                    False       -0.4215\n",
      "989                    False        0.6369\n",
      "990                    False       -0.3182\n",
      "991                    False       -0.6705\n",
      "992                     True       -0.2960\n",
      "993                    False       -0.3612\n",
      "994                    False        0.8126\n",
      "995                    False       -0.5526\n",
      "996                    False       -0.1027\n",
      "997                    False       -0.4767\n",
      "998                     True       -0.3595\n",
      "999                     True       -0.3182\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles = allDData['request_title']\n",
    "\n",
    "df_d = pd.DataFrame(data = allDData)\n",
    "\n",
    "df_d = df_d[['request_title', 'requester_received_pizza']]\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = analyser.polarity_scores(sentence)\n",
    "    snt['compund']\n",
    "    #print(\"{:-<40} {}\".format(sentence, str(snt)))\n",
    "    #print(snt['compound'])\n",
    "    \n",
    "scores_d = []\n",
    "\n",
    "for title in titles:\n",
    "    scores_d.append(analyser.polarity_scores(title)['compound'])\n",
    "\n",
    "df_d[\"Vader Scores\"] = scores_d\n",
    "\n",
    "df_d = df_d.drop('request_title', axis = 1)\n",
    "\n",
    "print(df_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, C = 0.001\n",
      "---------------------------------------------------------------------------\n",
      "Accuracy:  0.74\n",
      "Area under curve of ROC:  0.5\n",
      "Classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      1.00      0.85       740\n",
      "       True       0.00      0.00      0.00       260\n",
      "\n",
      "avg / total       0.55      0.74      0.63      1000\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tTitles = allTData['request_title']\n",
    "dTitles = allDData['request_title']\n",
    "\n",
    "titleTSentiment = []\n",
    "titleDSentiment = []\n",
    "\n",
    "for title in tTitles:\n",
    "    snt = analyser.polarity_scores(title)\n",
    "    compoundScore = snt['compound']\n",
    "    titleTSentiment.append(compoundScore)\n",
    "\n",
    "titleTSentiment = pd.DataFrame(titleTSentiment)\n",
    "    \n",
    "for title in dTitles:\n",
    "    snt = analyser.polarity_scores(title)\n",
    "    compoundScore = snt['compound']\n",
    "    titleDSentiment.append(compoundScore)\n",
    "\n",
    "titleDSentiment = pd.DataFrame(titleDSentiment)\n",
    "\n",
    "C = 100\n",
    "modelLogit = LogisticRegression(penalty = 'l2', C = C)\n",
    "\n",
    "trainLabel = allTData['requester_received_pizza']\n",
    "devLabel = allDData['requester_received_pizza']\n",
    "\n",
    "modelLogit.fit(titleTSentiment,trainLabel)\n",
    "score_rep(devLabel,modelLogit.predict(titleDSentiment),'Logistic Regression, C = 0.001')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reducing vocabulary (doesn't work)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Keep this random seed here to make comparison easier.\n",
    "np.random.seed(101)\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "# Countvectorizer options: turns on lower case, strip accents, and stop-words\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.95, lowercase=True, stop_words='english', \n",
    "                             strip_accents='unicode', ngram_range=(1,4))\n",
    "\n",
    "def LR1(C):\n",
    "\n",
    "    \"\"\"\n",
    "    Function estimates an LR with l1 regularization and counts number of nonzero weights\n",
    "    Returns coefficient array\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess data\n",
    "    train_data_v = vectorizer.fit_transform(data_preprocessor(trainCorpus))\n",
    "    dev_data_v = vectorizer.transform(data_preprocessor(devCorpus))\n",
    "\n",
    "    # Run the LR regression, l1 regularization, solving using liblinear [note: l1 doesn't work with multinomial]\n",
    "    clf = LogisticRegression(penalty='l1', C=C)\n",
    "    clf.fit(train_data_v,trainLabel)\n",
    "    test_predicted_labels = clf.predict(dev_data_v)\n",
    "\n",
    "    print ('\\nLogistic Regression f1-score with C = %6.3f:' %C )\n",
    "    print (metrics.f1_score(devLabel,test_predicted_labels))\n",
    "    print ('Number of non-zero elements: %d' %(np.count_nonzero(clf.coef_)))\n",
    "\n",
    "    return clf.coef_\n",
    "\n",
    "def LR2(C,lvocab):\n",
    "    \"\"\"\n",
    "    Calls LR with l2 for given vocab\n",
    "    Returns vocab size and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Define new vectorizer with vocab = vocab\n",
    "    vectorizer1 = CountVectorizer(lowercase=True, strip_accents='unicode',\n",
    "                                  stop_words='english',vocabulary=lvocab)\n",
    "\n",
    "    # Preprocess data using new vectorizer\n",
    "    train_data_v1 = vectorizer1.fit_transform(data_preprocessor(trainCorpus))\n",
    "    dev_data_v1 = vectorizer1.transform(data_preprocessor(devCorpus))\n",
    "\n",
    "    # Run the LR regression, l2 regularization, solving using sag\n",
    "    clf1 = LogisticRegression(penalty='l2', tol=0.01, C=C)\n",
    "    clf1.fit(train_data_v1,trainLabel)\n",
    "    test_predicted_labels = clf1.predict(dev_data_v1)\n",
    "\n",
    "    print ('\\nLogistic Regression (using l2) f1-score with C = %6.3f:' %C )\n",
    "    print (metrics.f1_score(devLabel,test_predicted_labels))\n",
    "    score_rep(devLabel,test_predicted_labels,'Logistic Regression')\n",
    "\n",
    "\n",
    "    return (len(lvocab),metrics.f1_score(devLabel,test_predicted_labels) )\n",
    "\n",
    "def create_vocab_list(s):\n",
    "    \"\"\"\n",
    "    inputs - clf.coef_\n",
    "    output - list of vocabulary\n",
    "    creates a list of vocabulary corresponding to non-zero features\n",
    "    \"\"\"\n",
    "\n",
    "    def build_vocab (s):\n",
    "        temp = []\n",
    "        for i in range (len(s)):\n",
    "            temp.append(s[i])\n",
    "        return temp\n",
    "\n",
    "    def build_vocab_list(s):\n",
    "        temp = []\n",
    "        for i in range(1):\n",
    "            y = np.nonzero(s[i])\n",
    "            y = list(y[0])\n",
    "            temp = temp + build_vocab(y)\n",
    "        temp = list(set(temp))    \n",
    "        return temp\n",
    "\n",
    "    vocab = build_vocab_list(s) \n",
    "\n",
    "    x = vectorizer.get_feature_names()\n",
    "\n",
    "    temp = []\n",
    "\n",
    "    for vocab in vocab:\n",
    "        temp.append(x[vocab])\n",
    "\n",
    "    return temp\n",
    "\n",
    "# Main program\n",
    "\n",
    "C = [1e-1, 1] #2, 5, 10, 20, 50, 100, 200, 500, 1000 ] # Run over various C\n",
    "\n",
    "a, b = [], []\n",
    "for C in C:\n",
    "    z = LR1(C) # Call this function to estimate LR with L1, z is the matrix of coef\n",
    "    lvocab = create_vocab_list(z) # Call this function to create vocab list where coef not equal zero\n",
    "    print ('Vocabulary size: %d' %len(lvocab))\n",
    "    x, y = LR2(C,lvocab) # Call new LR estimate with L2\n",
    "    a.append(x)\n",
    "    b.append(y)\n",
    "\n",
    "# Plot vocabulary size vs accuracy\n",
    "\n",
    "plt.plot(a,b)\n",
    "plt.xlabel('Vocabulary')\n",
    "plt.ylabel('Accuracy (F1 score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using l1 to choose features (doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the best regularization\n",
    "regStrength = [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 6.0, 10.0]\n",
    "\n",
    "\n",
    "for c in regStrength:\n",
    "    modelLogit = LogisticRegression(penalty='l1', C=c)\n",
    "    modelLogit.fit(tVector_p, trainLabel)\n",
    "    logitScore = round(modelLogit.score(dVector_p, devLabel), 4)\n",
    "    print(\"For C = \", c, \"Logistic regression accuracy:\", logitScore)\n",
    "    score_rep(devLabel,modelLogit.predict(dVector_p),'Logistic Regression, C = 0.01')\n",
    "\n",
    "\n",
    "# although the best score comes from c=.001, the bet F1-score \n",
    "# comes from c=.5, and this gives better weight options\n",
    "modelLogit = LogisticRegression(penalty='l1', C=.5, tol = .1)\n",
    "modelLogit.fit(tVector_p, trainLabel)\n",
    "score_rep(devLabel,modelLogit.predict(dVector_p),'Logistic Regression')\n",
    "roc_curve1(devLabel, modelLogit.predict_proba(dVector_p)[:,0])\n",
    "\n",
    "\n",
    "print(max(modelLogit.coef_[0]))\n",
    "numWeights = 5\n",
    "\n",
    "sortIndex = np.argsort(modelLogit.coef_)\n",
    "iLen = len(sortIndex[0])\n",
    "print(\"\\nTop\", numWeights, \"Weighted Features:\")\n",
    "\n",
    "for index in range((iLen - numWeights) , iLen):\n",
    "    lookup = sortIndex[0][index]\n",
    "    print(lookup)\n",
    "    weight =  modelLogit.coef_[0][lookup]\n",
    "    print(vectorizer.get_feature_names()[sortIndex[0][index]], weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA/LDA to reduce dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = TruncatedSVD(n_components=600)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.95, lowercase=True, stop_words='english', \n",
    "                             strip_accents='unicode', ngram_range=(1,1))\n",
    "\n",
    "tVector = vectorizer.fit_transform(data_preprocessor(trainCorpus))\n",
    "dVector = vectorizer.transform(data_preprocessor(devCorpus))\n",
    "\n",
    "#print(tVector.shape)\n",
    "\n",
    "tVector_s = pca.fit(tVector)\n",
    "dVector_s = pca.fit(dVector)\n",
    "\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.axes([.2, .2, .7, .7])\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_')\n",
    "plt.show()\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=600)\n",
    "\n",
    "RF.fit(tVector, trainLabel)\n",
    "score_rep(devLabel, RF.predict(dVector),'Random Forest')\n",
    "roc_curve1(devLabel, RF.predict_proba(dVector)[:,0])\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "clf = BernoulliNB(alpha=alpha)\n",
    "\n",
    "clf.fit(tVector, trainLabel)\n",
    "score_rep(devLabel, clf.predict(dVector),'Naive Bayes, alpha = 0.01')\n",
    "roc_curve1(devLabel, clf.predict_proba(dVector)[:,0])\n",
    "\n",
    "C = 100 #(For now)\n",
    "\n",
    "modelLogit = LogisticRegression(penalty='l2', C=C)\n",
    "\n",
    "modelLogit.fit(tVector,trainLabel)\n",
    "score_rep(devLabel,modelLogit.predict(dVector),'Logistic Regression, C = 0.01')\n",
    "roc_curve1(devLabel, modelLogit.predict_proba(dVector)[:,0])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
