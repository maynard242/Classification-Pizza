{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# W207 Final Project\n",
    "Erika, Jen Jen, Geoff, Leslie\n",
    "\n",
    "(In Python 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As of 3/35\n",
    "\n",
    "Outline:\n",
    "\n",
    "* Data Pre-Processing  \n",
    "* Simple Feature Selection\n",
    "* Basline Models\n",
    "* Possible Approaches\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 1 Loading and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Import Libraries ##\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pandas import *\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of the normalized Data: (3040, 32)\n",
      "\n",
      "normalized data columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n"
     ]
    }
   ],
   "source": [
    "## Get Data ##\n",
    "\n",
    "#reference on data: https://www.kaggle.com/c/random-acts-of-pizza/data\n",
    "# pull in the training and test data\n",
    "with open('/Users/Jen2/Desktop/W207/project/train.json', encoding='utf-8') as data_file:\n",
    "#with open('/home/levi/Documents/W207_Proj/data/train.json', encoding='utf-8') as data_file:\n",
    "    trainData = json.loads(data_file.read())   \n",
    "with open('/Users/Jen2/Desktop/W207/project/test.json', encoding='utf-8') as data_file:\n",
    "#with open('/home/levi/Documents/W207_Proj/data/train.json', encoding='utf-8') as data_file:\n",
    "    testData = json.loads(data_file.read())    \n",
    "\n",
    "# create a dev data set \n",
    "devData = trainData[0:1000]\n",
    "trainData = trainData[1000:]\n",
    "\n",
    "# show how the data looks in its original format\n",
    "#pprint(\"data in json format:\")\n",
    "#pprint(trainData[1])\n",
    "\n",
    "# create a normalized view\n",
    "allTData = json_normalize(trainData)\n",
    "print(\"\\nSize of the normalized Data:\", allTData.shape)\n",
    "print(\"\\nnormalized data columns:\", list(allTData))\n",
    "\n",
    "allDData = json_normalize(devData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.1 Text data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3040, 1)\n"
     ]
    }
   ],
   "source": [
    "## Create subsets of data for analysis ###\n",
    "\n",
    "# create a flat dataset without the subreddits list\n",
    "flatData = allTData.drop('requester_subreddits_at_request', 1)\n",
    "# create a separate dataset with just subreddits, indexed on request id\n",
    "# we can creata a count vector on the words, run Naive Bayes against it, \n",
    "# and add the probabilities to our flat dataset\n",
    "subredTData = allTData[['request_id','requester_subreddits_at_request']]\n",
    "subredTData.set_index('request_id', inplace=True)\n",
    "\n",
    "subredDData= allDData[['request_id','requester_subreddits_at_request']]\n",
    "subredDData.set_index('request_id', inplace=True)\n",
    "\n",
    "# our training labels\n",
    "trainLabel = allTData['requester_received_pizza']\n",
    "\n",
    "devLabel = allDData['requester_received_pizza']\n",
    "\n",
    "# what do these look like?\n",
    "#print(list(flatData))\n",
    "print(subredTData.shape)\n",
    "#print(subredTData['requester_subreddits_at_request'][1])\n",
    "\n",
    "# create a corpus of subreddits to vectorize\n",
    "trainCorpus = []\n",
    "for index in range(len(subredTData)):\n",
    "    trainCorpus.append(' '.join(subredTData['requester_subreddits_at_request'][index]))\n",
    "\n",
    "devCorpus = []\n",
    "for index in range(len(subredDData)):\n",
    "    devCorpus.append(' '.join(subredDData['requester_subreddits_at_request'][index]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"FoodstuffsAllAround IAmA RandomActsOfCookies RandomActsofCards RandomKindness Random_Acts_Of_Pizza comiccon cosplay cosplayers So it's been a while since it's happened, but yeah. Just got dumped by a girl I like... My brother has used up pretty much everything in the freezer. I would really appreciate a pizza right now... So it's been a while since it's happened, but yeah. Just got dumped by a girl I like... My brother has used up pretty much everything in the freezer. I would really appreciate a pizza right now... [Request] Just got dumped, no food in the freezer. Pizza?\", \"AskReddit Guitar Jazz Music NSFW_GIF Psychonaut RoomPorn StAugustine TwoXChromosomes WTF YouShouldKnow atheism aww bakedart catpictures cats crochet dubstep ents entwives food funny gonewild hiphopheads listentothis meetup offbeat pics realpics self sex tattoos treecomics treemusic trees videos vinyl zombies My boyfriend and I live in Saint Augustine, Florida and have been having a rough time financially the past few months.  In and out of various jobs, we've had to survive off of coscto sized ramen packs, and pasta and olive oil.  I applied for food stamps a couple days ago, and am waiting to hear back from them.  It's getting a little trite, and we're quite hungry tonight, a hot pizza would be a delight.  We'll happily pay it forward in the future.  Much love. My boyfriend and I live in Saint Augustine, Florida and have been having a rough time financially the past few months.  In and out of various jobs, we've had to survive off of coscto sized ramen packs, and pasta and olive oil.  I applied for food stamps a couple days ago, and am waiting to hear back from them.  It's getting a little trite, and we're quite hungry tonight, a hot pizza would be a delight.  We'll happily pay it forward in the future.  Much love. [Request]  Saint Augustine, US.  Boyfriend and I have no money till next week, and are awaiting food stamps approval.\", \"Albany AskReddit Brooklyn Favors ImGoingToHellForThis Random_Acts_Of_Amazon Random_Acts_Of_Pizza YouShouldKnow cars cigars gaming pics shutupandtakemymoney ualbany upstate_new_york videos I seriously love buffalo chicken pizza. Like, straight up addicted. There's a local pizzeria that delivers and they make the best buffalo chicken pizza I've ever had; however if you dont feel safe with that or have a Giftcard to a chain I could care less, I just want a buffalo chicken pizza soooo bad!  I seriously love buffalo chicken pizza. Like, straight up addicted. There's a local pizzeria that delivers and they make the best buffalo chicken pizza I've ever had; however if you dont feel safe with that or have a Giftcard to a chain I could care less, I just want a buffalo chicken pizza soooo bad!  [Request] I'd love a Buffalo Chicken Puzza!\"]\n",
      "[0, 0, 1]\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      " [' Hi I am in need of food for my 4 children we are a military family that has really hit hard times and we have exahusted all means of help just to be able to feed my family and make it through another night is all i ask i know our blessing is coming so whatever u can find in your heart to give is greatly appreciated Hi I am in need of food for my 4 children we are a military family that has really hit hard times and we have exahusted all means of help just to be able to feed my family and make it through another night is all i ask i know our blessing is coming so whatever u can find in your heart to give is greatly appreciated Request Colorado Springs Help Us Please', 'AskReddit Eve IAmA MontereyBay RandomKindness RedditBiography dubstep gamecollecting gaming halo i18n techsupport I spent the last money I had on gas today. Im broke until next Thursday :( I spent the last money I had on gas today. Im broke until next Thursday :( [Request] California, No cash and I could use some dinner', \" My girlfriend decided it would be a good idea to get off at Perth bus station when she was coming to visit me and has since had to spend all her money on a taxi to get to me here in Dundee. Any chance some kind soul would get us some pizza since we don't have any cash anymore? My girlfriend decided it would be a good idea to get off at Perth bus station when she was coming to visit me and has since had to spend all her money on a taxi to get to me here in Dundee. Any chance some kind soul would get us some pizza since we don't have any cash anymore? [Request] Hungry couple in Dundee, Scotland would love some pizza!\"]\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# combine all text sources into a single corpus\n",
    "fldTText = allTData[['request_id','request_text', 'request_text_edit_aware', 'request_title']]\n",
    "fldDText = allDData[['request_id','request_text', 'request_text_edit_aware', 'request_title']]\n",
    "\n",
    "trainCorpus = []\n",
    "for index in range(len(subredTData)):\n",
    "    a = ' '.join(subredTData['requester_subreddits_at_request'][index])\n",
    "    b = (a, fldTText['request_text'][index], fldTText['request_text_edit_aware'][index],\n",
    "        fldTText['request_title'][index])\n",
    "    trainCorpus.append(' '.join(b))\n",
    "\n",
    "devCorpus = []\n",
    "for index in range(len(subredDData)):\n",
    "    a = ' '.join(subredDData['requester_subreddits_at_request'][index])\n",
    "    b = (a, fldDText['request_text'][index], fldDText['request_text_edit_aware'][index],\n",
    "         fldDText['request_title'][index])\n",
    "    devCorpus.append(' '.join(b))\n",
    "\n",
    "# Print 3 examples  \n",
    "print (trainCorpus[:3])\n",
    "labels = trainLabel.astype(int)\n",
    "labels = list(labels)\n",
    "print(labels[:3])\n",
    "print('-'*75)\n",
    "\n",
    "print ('\\n' , devCorpus[:3])\n",
    "labels_dev = devLabel.astype(int)\n",
    "labels_dev = list(labels_dev)\n",
    "print(labels_dev[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.2 User status analysis (votes, flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CREATE SUBSETS FOR USER STATUS ANALYSIS ##\n",
    "\n",
    "# subsets for upvotes-downvotes and upvotes+downvotes at time of request and retrieval\n",
    "diffTrequest = allTData['requester_upvotes_minus_downvotes_at_request']\n",
    "diffDrequest = allDData['requester_upvotes_minus_downvotes_at_request']\n",
    "diffTretrieval = allTData['requester_upvotes_minus_downvotes_at_retrieval']\n",
    "diffDretrieval = allDData['requester_upvotes_minus_downvotes_at_retrieval']\n",
    "totalvotesTrequest = allTData['requester_upvotes_plus_downvotes_at_request']\n",
    "totalvotesDrequest = allDData['requester_upvotes_plus_downvotes_at_request']\n",
    "totalvotesTretrieval = allTData['requester_upvotes_plus_downvotes_at_retrieval']\n",
    "totalvotesDretrieval = allDData['requester_upvotes_plus_downvotes_at_retrieval']\n",
    "\n",
    "# subsets for flair (training data only)\n",
    "Tflair = allTData['requester_user_flair'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY STATISTICS FOR UPVOTES-DOWNVOTES AT REQUEST AND AT RETRIEVAL\n",
      "\n",
      "Summary for upvotes-downvotes at request:\n",
      "count      3040.00\n",
      "mean       1134.19\n",
      "std        3744.32\n",
      "min        -173.00\n",
      "25%           3.00\n",
      "50%         183.50\n",
      "75%        1166.00\n",
      "max      155010.00\n",
      "Name: requester_upvotes_minus_downvotes_at_request, dtype: float64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Summary for upvotes-downvotes at retrieval:\n",
      "count      3040.00\n",
      "mean       2713.92\n",
      "std        6507.20\n",
      "min        -173.00\n",
      "25%          23.00\n",
      "50%         705.50\n",
      "75%        3301.25\n",
      "max      223708.00\n",
      "Name: requester_upvotes_minus_downvotes_at_retrieval, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "## SUMMARY STATISTICS FOR UPVOTES-DOWNVOTES AT REQUEST AND AT RETRIEVAL ##\n",
    "\n",
    "print(\"SUMMARY STATISTICS FOR UPVOTES-DOWNVOTES AT REQUEST AND AT RETRIEVAL\")\n",
    "# UPVOTES-DOWNVOTES AT REQUEST ----------------------\n",
    "print(\"\\nSummary for upvotes-downvotes at request:\")\n",
    "print(round(diffTrequest.describe(),2), end=\"\\n\\n\")\n",
    "\n",
    "# UPVOTES-DOWNVOTES AT RETRIEVAL -------------------\n",
    "print(\"-\"*100)\n",
    "print(\"Summary for upvotes-downvotes at retrieval:\")\n",
    "print(round(diffTretrieval.describe(),2), end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING NEW PARAMETER - REQUEST-RETRIEVAL:  to represent change in counts from upvotes-downvotes from time of request to time of retrieval.\n",
      "\n",
      "STATUS TRAINING DATA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request</th>\n",
       "      <th>Retrieval</th>\n",
       "      <th>Request-Retrieval</th>\n",
       "      <th>Got Pizza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>97</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278</td>\n",
       "      <td>664</td>\n",
       "      <td>386</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>596</td>\n",
       "      <td>390</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124</td>\n",
       "      <td>5049</td>\n",
       "      <td>4925</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Request  Retrieval  Request-Retrieval Got Pizza\n",
       "0       87         97                 10     False\n",
       "1      278        664                386     False\n",
       "2      206        596                390      True\n",
       "3        3          3                  0     False\n",
       "4      124       5049               4925      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "STATUS DEVELOPMENT DATA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request</th>\n",
       "      <th>Retrieval</th>\n",
       "      <th>Request-Retrieval</th>\n",
       "      <th>Got Pizza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>4258</td>\n",
       "      <td>4224</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1121</td>\n",
       "      <td>1225</td>\n",
       "      <td>104</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Request  Retrieval  Request-Retrieval Got Pizza\n",
       "0        0          1                  1     False\n",
       "1       34       4258               4224     False\n",
       "2        0          3                  3     False\n",
       "3       54         59                  5     False\n",
       "4     1121       1225                104     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "## CREATING NEW PARAMETER: the change in upvotes-downvotes from time of request to time of retrieval ##\n",
    "\n",
    "# user status with new parameter for training data\n",
    "allTData['request_to_retrieval_upvotes_minus_downvotes'] = diffTretrieval - diffTrequest\n",
    "diffTcombined = allTData[['requester_upvotes_minus_downvotes_at_request','requester_upvotes_minus_downvotes_at_retrieval',\n",
    "                          'request_to_retrieval_upvotes_minus_downvotes','requester_received_pizza']].copy()\n",
    "# rename column headings\n",
    "diffTcombined.columns = ['Request', 'Retrieval', 'Request-Retrieval', 'Got Pizza']\n",
    "print(\"ADDING NEW PARAMETER - REQUEST-RETRIEVAL:  to represent change in counts from upvotes-downvotes from time of request to time of retrieval.\")\n",
    "print(\"\\nSTATUS TRAINING DATA\")\n",
    "display(diffTcombined.head())\n",
    "\n",
    "# user status with new parameter for training data\n",
    "allDData['request_to_retrieval_upvotes_minus_downvotes'] = diffDretrieval - diffDrequest\n",
    "diffDcombined = allDData[['requester_upvotes_minus_downvotes_at_request','requester_upvotes_minus_downvotes_at_retrieval',\n",
    "                          'request_to_retrieval_upvotes_minus_downvotes','requester_received_pizza']].copy()\n",
    "# rename columne headings\n",
    "diffDcombined.columns = ['Request', 'Retrieval', 'Request-Retrieval', 'Got Pizza']\n",
    "print(\"\\n\")\n",
    "print(\"STATUS DEVELOPMENT DATA\")\n",
    "display(diffDcombined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SUMMARY STATISTICS FOR UPVOTES-DOWNVOTES AT REQUEST AND AT RETRIEVAL, GROUPED BY PIZZA SUCCESS\n",
      "\n",
      "Group upvotes-downvotes at request by pizza success:\n",
      "\n",
      "                   Request\n",
      "Got Pizza                 \n",
      "False     count    2306.00\n",
      "          mean     1033.28\n",
      "          std      2530.16\n",
      "          min      -173.00\n",
      "          25%         1.00\n",
      "          50%       138.00\n",
      "          75%      1048.75\n",
      "          max     68436.00\n",
      "True      count     734.00\n",
      "          mean     1451.22\n",
      "          std      6153.27\n",
      "          min       -39.00\n",
      "          25%        28.25\n",
      "          50%       312.00\n",
      "          75%      1524.50\n",
      "          max    155010.00\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Group upvotes-downvotes at retrieval by pizza success:\n",
      "\n",
      "                 Retrieval\n",
      "Got Pizza                 \n",
      "False     count    2306.00\n",
      "          mean     2363.97\n",
      "          std      4631.33\n",
      "          min      -173.00\n",
      "          25%        11.00\n",
      "          50%       520.50\n",
      "          75%      2852.75\n",
      "          max     97807.00\n",
      "True      count     734.00\n",
      "          mean     3813.34\n",
      "          std     10320.40\n",
      "          min        -9.00\n",
      "          25%       182.25\n",
      "          50%      1234.50\n",
      "          75%      4720.50\n",
      "          max    223708.00\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## SUMMARY STATISTICS FOR UPVOTES-DOWNVOTES AT REQUEST AND AT RETRIEVAL ##\n",
    "\n",
    "# upvotes-downvotes at request, grouped by pizza success -------------------------\n",
    "print(\"\\n\\nSUMMARY STATISTICS FOR UPVOTES-DOWNVOTES AT REQUEST AND AT RETRIEVAL, GROUPED BY PIZZA SUCCESS\")\n",
    "\n",
    "diffreq_pizzas = allTData[['requester_upvotes_minus_downvotes_at_request','requester_received_pizza']].copy()\n",
    "diffreq_pizzas.columns = ['Request', 'Got Pizza']\n",
    "pizza_diff_request = diffreq_pizzas.groupby(['Got Pizza'])\n",
    "print(\"\\nGroup upvotes-downvotes at request by pizza success:\\n\")\n",
    "print(round(pizza_diff_request.describe(), 2))\n",
    "\n",
    "# upvotes-downvotes at retrieval, grouped by pizza success -------------------------\n",
    "diffretrieve_pizzas = allTData[['requester_upvotes_minus_downvotes_at_retrieval','requester_received_pizza']].copy()\n",
    "diffretrieve_pizzas.columns = ['Retrieval', 'Got Pizza']\n",
    "pizza_diff_retrieval = diffretrieve_pizzas.groupby(['Got Pizza'])\n",
    "print(\"\\n\")\n",
    "print(\"-\"*100)\n",
    "print(\"\\nGroup upvotes-downvotes at retrieval by pizza success:\\n\")\n",
    "print(round(pizza_diff_retrieval.describe(), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Types of Flair and Pizza Success\n",
      "\n",
      "    Flair Got Pizza\n",
      "0    None     False\n",
      "1    None     False\n",
      "2  shroom      True\n",
      "3    None     False\n",
      "4  shroom      True\n",
      "5    None     False\n",
      "6    None     False\n",
      "7    None     False\n",
      "8    None     False\n",
      "9  shroom      True\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Group flair by pizza success:\n",
      "\n",
      "                   Flair\n",
      "Got Pizza               \n",
      "False     count        0\n",
      "          unique       0\n",
      "True      count      734\n",
      "          unique       2\n",
      "          top     shroom\n",
      "          freq       683\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       0.0\n",
      "3       NaN\n",
      "4       0.0\n",
      "5       NaN\n",
      "6       NaN\n",
      "7       NaN\n",
      "8       NaN\n",
      "9       0.0\n",
      "10      NaN\n",
      "11      NaN\n",
      "12      NaN\n",
      "13      NaN\n",
      "14      NaN\n",
      "15      NaN\n",
      "16      1.0\n",
      "17      NaN\n",
      "18      NaN\n",
      "19      NaN\n",
      "20      0.0\n",
      "21      NaN\n",
      "22      0.0\n",
      "23      NaN\n",
      "24      NaN\n",
      "25      NaN\n",
      "26      NaN\n",
      "27      NaN\n",
      "28      NaN\n",
      "29      0.0\n",
      "       ... \n",
      "3010    NaN\n",
      "3011    NaN\n",
      "3012    1.0\n",
      "3013    NaN\n",
      "3014    NaN\n",
      "3015    NaN\n",
      "3016    NaN\n",
      "3017    NaN\n",
      "3018    NaN\n",
      "3019    NaN\n",
      "3020    NaN\n",
      "3021    NaN\n",
      "3022    NaN\n",
      "3023    NaN\n",
      "3024    1.0\n",
      "3025    NaN\n",
      "3026    NaN\n",
      "3027    NaN\n",
      "3028    NaN\n",
      "3029    NaN\n",
      "3030    NaN\n",
      "3031    NaN\n",
      "3032    NaN\n",
      "3033    NaN\n",
      "3034    NaN\n",
      "3035    NaN\n",
      "3036    0.0\n",
      "3037    NaN\n",
      "3038    NaN\n",
      "3039    NaN\n",
      "Name: Flair, dtype: float64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d37fc61a2f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# binarize categorical features in FLAIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mbin_flair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Flair'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shroom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PIF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_flair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mbin_flair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOut of 734 pizza recipients, 683 did not PIF and 51 did PIF.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "## USER FLAIR ##\n",
    "# None = no pizza\n",
    "#'shroom' = got pizza without 'pay it forward' (PIF)\n",
    "# PIF' = got pizza and paid forward\n",
    "\n",
    "flair = allTData[['requester_user_flair','requester_received_pizza']].copy()\n",
    "flair.columns = ['Flair', 'Got Pizza']\n",
    "print(\"\\n\")\n",
    "print(\"Types of Flair and Pizza Success\\n\")\n",
    "print(flair.head(10))\n",
    "pizza_flair = flair.groupby(['Got Pizza'])\n",
    "print(\"\\n\")\n",
    "print(\"-\"*100)\n",
    "print(\"\\nGroup flair by pizza success:\\n\")\n",
    "print(round(pizza_flair.describe(),2))\n",
    "\n",
    "# binarize categorical features in FLAIR\n",
    "bin_flair = flair['Flair'].replace(['None', 'shroom', 'PIF'], [-1, 0, 1])\n",
    "bin_flair.value_counts()\n",
    "print(\"\\nOut of 734 pizza recipients, 683 did not PIF and 51 did PIF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request</th>\n",
       "      <th>Retrieval</th>\n",
       "      <th>Request-Retrieval</th>\n",
       "      <th>Request Z-score</th>\n",
       "      <th>Retrieval Z-score</th>\n",
       "      <th>Request-Retrieval Z-score</th>\n",
       "      <th>requester_user_flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>97</td>\n",
       "      <td>10</td>\n",
       "      <td>86.69704</td>\n",
       "      <td>96.582867</td>\n",
       "      <td>9.604169</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278</td>\n",
       "      <td>664</td>\n",
       "      <td>386</td>\n",
       "      <td>277.69704</td>\n",
       "      <td>663.582867</td>\n",
       "      <td>385.604169</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>596</td>\n",
       "      <td>390</td>\n",
       "      <td>205.69704</td>\n",
       "      <td>595.582867</td>\n",
       "      <td>389.604169</td>\n",
       "      <td>shroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.69704</td>\n",
       "      <td>2.582867</td>\n",
       "      <td>-0.395831</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124</td>\n",
       "      <td>5049</td>\n",
       "      <td>4925</td>\n",
       "      <td>123.69704</td>\n",
       "      <td>5048.582867</td>\n",
       "      <td>4924.604169</td>\n",
       "      <td>shroom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Request  Retrieval  Request-Retrieval  Request Z-score  Retrieval Z-score  \\\n",
       "0       87         97                 10         86.69704          96.582867   \n",
       "1      278        664                386        277.69704         663.582867   \n",
       "2      206        596                390        205.69704         595.582867   \n",
       "3        3          3                  0          2.69704           2.582867   \n",
       "4      124       5049               4925        123.69704        5048.582867   \n",
       "\n",
       "   Request-Retrieval Z-score requester_user_flair  \n",
       "0                   9.604169                 None  \n",
       "1                 385.604169                 None  \n",
       "2                 389.604169               shroom  \n",
       "3                  -0.395831                 None  \n",
       "4                4924.604169               shroom  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request</th>\n",
       "      <th>Retrieval</th>\n",
       "      <th>Request-Retrieval</th>\n",
       "      <th>Request Z-score</th>\n",
       "      <th>Retrieval Z-score</th>\n",
       "      <th>Request-Retrieval Z-score</th>\n",
       "      <th>requester_user_flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.340583</td>\n",
       "      <td>0.49824</td>\n",
       "      <td>0.512085</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>4258</td>\n",
       "      <td>4224</td>\n",
       "      <td>33.659417</td>\n",
       "      <td>4257.49824</td>\n",
       "      <td>4223.512085</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.340583</td>\n",
       "      <td>2.49824</td>\n",
       "      <td>2.512085</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>53.659417</td>\n",
       "      <td>58.49824</td>\n",
       "      <td>4.512085</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1121</td>\n",
       "      <td>1225</td>\n",
       "      <td>104</td>\n",
       "      <td>1120.659417</td>\n",
       "      <td>1224.49824</td>\n",
       "      <td>103.512085</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Request  Retrieval  Request-Retrieval  Request Z-score  Retrieval Z-score  \\\n",
       "0        0          1                  1        -0.340583            0.49824   \n",
       "1       34       4258               4224        33.659417         4257.49824   \n",
       "2        0          3                  3        -0.340583            2.49824   \n",
       "3       54         59                  5        53.659417           58.49824   \n",
       "4     1121       1225                104      1120.659417         1224.49824   \n",
       "\n",
       "   Request-Retrieval Z-score requester_user_flair  \n",
       "0                   0.512085                 None  \n",
       "1                4223.512085                 None  \n",
       "2                   2.512085                 None  \n",
       "3                   4.512085                 None  \n",
       "4                 103.512085                 None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## CONVERT UPVOTES-DOWNVOTES SUBSETS INTO Z-SCORES FOR STANDARDIZATION ##\n",
    "## CREATE FINAL SUBSET FOR UPVOTES-DOWNVOTES, Z-SCORES, AND FLAIR ##\n",
    "\n",
    "# Z-scores for training data\n",
    "statusTtrain = allTData[['requester_upvotes_minus_downvotes_at_request','requester_upvotes_minus_downvotes_at_retrieval',\n",
    "                          'request_to_retrieval_upvotes_minus_downvotes']].copy()\n",
    "statusTtrain.columns = ['Request', 'Retrieval', 'Request-Retrieval']\n",
    "for col in statusTtrain:\n",
    "    zscore_col = col + \" Z-score\"\n",
    "    statusTtrain[zscore_col] = (statusTtrain[col] - statusTtrain[col].mean() / statusTtrain[col].std(ddof=0))\n",
    "statusTtrain = (statusTtrain).join(allTData['requester_user_flair'])\n",
    "display(statusTtrain.head())\n",
    "\n",
    "# Z-scores for development data\n",
    "statusDtrain = allDData[['requester_upvotes_minus_downvotes_at_request','requester_upvotes_minus_downvotes_at_retrieval',\n",
    "                          'request_to_retrieval_upvotes_minus_downvotes']].copy()\n",
    "statusDtrain.columns = ['Request', 'Retrieval', 'Request-Retrieval']\n",
    "\n",
    "for col in statusDtrain:\n",
    "    zscore_dev_col = col + \" Z-score\"\n",
    "    statusDtrain[zscore_dev_col] = (statusDtrain[col] - statusDtrain[col].mean() / statusDtrain[col].std(ddof=0))\n",
    "statusDtrain = (statusDtrain).join(allDData['requester_user_flair'])\n",
    "display(statusDtrain.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 2. Simple Feature Selection and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Simple Pre-Processing\n",
    "\n",
    "def data_preprocessor(s):\n",
    "    \"\"\"\n",
    "    Note: this function pre-processors data:\n",
    "    (1) removes non-alpha characters\n",
    "    (2) converts digits to 'number'\n",
    "    (3) regularizes spaces (although CountVectorizer ignores this unless they are part of words)\n",
    "    (4) reduces word size to n\n",
    "    \"\"\"\n",
    "\n",
    "    s = [re.sub(r'[?|$|.|!|@|\\n|(|)|<|>|_|-|,|\\']',r' ',s) for s in s] # strip out non-alpha numeric char, replace with space\n",
    "    s = [re.sub(r'\\d+',r'number ',s) for s in s] # convert digits to number\n",
    "    s = [re.sub(r' +',r' ',s) for s in s] # convert multiple spaces to single space\n",
    "    \n",
    "    # This sets word size to n=5\n",
    "    num = 5\n",
    "    def set_word(s):\n",
    "        temp = []\n",
    "        for s in s:\n",
    "            x = s.split()\n",
    "            z = [elem[:num] for elem in x]\n",
    "            z = ' '.join(z)\n",
    "            temp.append(z)       \n",
    "        return temp\n",
    "    \n",
    "    s = set_word(s)\n",
    "    \n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw data:\n",
      "The size of the vocabulary for the training text data is 17213\n",
      "First 5 feature Names: ['000', '0000', '0011011001111000', '00243364', '00pm'] \n",
      "\n",
      "\n",
      "Pre-Processed data:\n",
      "The size of the vocabulary for the training text data is 10491\n",
      "First 5 feature Names: ['aaaaa', 'aan', 'ab', 'aback', 'aband'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up the data with CountVectorizer\n",
    "\n",
    "#vectorizer = CountVectorizer(lowercase=True, strip_accents='unicode',stop_words='english')\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1,lowercase=True)\n",
    "tVector = vectorizer.fit_transform(trainCorpus)\n",
    "dVector = vectorizer.transform(devCorpus)\n",
    "\n",
    "print ('\\nRaw data:')\n",
    "print (\"The size of the vocabulary for the training text data is\", tVector.shape[1])\n",
    "print (\"First 5 feature Names:\", vectorizer.get_feature_names()[1:6], \"\\n\")\n",
    "\n",
    "tVector_p = vectorizer.fit_transform(data_preprocessor(trainCorpus))\n",
    "dVector_p = vectorizer.transform(data_preprocessor(devCorpus))\n",
    "\n",
    "print ('\\nPre-Processed data:')\n",
    "print (\"The size of the vocabulary for the training text data is\", tVector_p.shape[1])\n",
    "print (\"First 5 feature Names:\", vectorizer.get_feature_names()[1:6], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 3. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Subreddit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C =  0.01 Logistic regression accuracy: 0.736\n",
      "For C =  0.01 Logistic regression (processed data) accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "C = 0.01 #(For now)\n",
    "\n",
    "modelLogit = LogisticRegression(penalty='l2', C=C)\n",
    "modelLogit.fit(tVector,trainLabel)\n",
    "logitScore = round(modelLogit.score(dVector, devLabel), 4)\n",
    "print(\"For C = \", C, \"Logistic regression accuracy:\", logitScore)\n",
    "\n",
    "modelLogit.fit(tVector_p,trainLabel)\n",
    "logitScore = round(modelLogit.score(dVector_p, devLabel), 4)\n",
    "print(\"For C = \", C, \"Logistic regression (processed data) accuracy:\", logitScore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB using raw data with alpha = 0.010: 0.719\n",
      "Bernoulli NB using processed data  with alpha = 0.010: 0.708\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "clf = BernoulliNB(alpha=alpha)\n",
    "clf.fit(tVector, trainLabel)\n",
    "test_predicted_labels = clf.predict(dVector) \n",
    "print ('Bernoulli NB using raw data with alpha = %1.3f:' %alpha, metrics.accuracy_score(devLabel,test_predicted_labels) )\n",
    "\n",
    "clf.fit(tVector_p, trainLabel)\n",
    "test_predicted_labels = clf.predict(dVector_p) \n",
    "print ('Bernoulli NB using processed data  with alpha = %1.3f:' %alpha, metrics.accuracy_score(devLabel,test_predicted_labels) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression More Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C =  0.0001 Logistic regression accuracy: 0.74\n",
      "For C =  0.001 Logistic regression accuracy: 0.74\n",
      "For C =  0.01 Logistic regression accuracy: 0.74\n",
      "For C =  0.1 Logistic regression accuracy: 0.734\n",
      "For C =  0.5 Logistic regression accuracy: 0.673\n",
      "For C =  1.0 Logistic regression accuracy: 0.653\n",
      "For C =  2.0 Logistic regression accuracy: 0.652\n",
      "For C =  6.0 Logistic regression accuracy: 0.645\n",
      "For C =  10.0 Logistic regression accuracy: 0.647\n",
      "1.29595926577\n",
      "\n",
      "Top 5 Weighted Features:\n",
      "6543\n",
      "orang 0.890284697911\n",
      "4411\n",
      "impre 0.959893755622\n",
      "4292\n",
      "hurti 1.03088990516\n",
      "10070\n",
      "weds 1.14781406623\n",
      "10175\n",
      "wiiu 1.29595926577\n"
     ]
    }
   ],
   "source": [
    "# get the best regularization\n",
    "regStrength = [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 6.0, 10.0]\n",
    "\n",
    "\n",
    "for c in regStrength:\n",
    "    modelLogit = LogisticRegression(penalty='l1', C=c)\n",
    "    modelLogit.fit(tVector_p, trainLabel)\n",
    "    logitScore = round(modelLogit.score(dVector_p, devLabel), 4)\n",
    "    print(\"For C = \", c, \"Logistic regression accuracy:\", logitScore)\n",
    "\n",
    "# although the best score comes from c=.001, the bet F1-score \n",
    "# comes from c=.5, and this gives better weight options\n",
    "modelLogit = LogisticRegression(penalty='l1', C=.5, tol = .1)\n",
    "modelLogit.fit(tVector_p, trainLabel)\n",
    "\n",
    "print(max(modelLogit.coef_[0]))\n",
    "numWeights = 5\n",
    "\n",
    "sortIndex = np.argsort(modelLogit.coef_)\n",
    "iLen = len(sortIndex[0])\n",
    "print(\"\\nTop\", numWeights, \"Weighted Features:\")\n",
    "\n",
    "for index in range((iLen - numWeights) , iLen):\n",
    "    lookup = sortIndex[0][index]\n",
    "    print(lookup)\n",
    "    weight =  modelLogit.coef_[0][lookup]\n",
    "    print(vectorizer.get_feature_names()[sortIndex[0][index]], weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Status models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with Request/Retrieval/Request-Retrieval Difference only\n",
      "Accuracy: 0.737\n",
      "F1 score: 0.0\n",
      "\n",
      "For model with Request / Retrieval Z-scores only :\n",
      "Accuracy: 0.737\n",
      "F1 score: 0.0\n",
      "\n",
      "For model with Request-Retrieval Z-Score only\n",
      "Accuracy: 0.738\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'shroom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-72f094d558c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mzcomb_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shroom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PIF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mzcomb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzcomb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mzcomb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzcomb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzcomb_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mzcomb_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzcomb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzcomb_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jen2/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, \n\u001b[0;32m-> 1142\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jen2/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/Jen2/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    371\u001b[0m                                       force_all_finite)\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'shroom'"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION MODELS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "# create training labels for pizza success\n",
    "train_labels = np.asarray(allTData['requester_received_pizza'])\n",
    "dev_labels = np.asarray(allDData['requester_received_pizza'])\n",
    "\n",
    "# Trial 1: Request / Retrieval \n",
    "diff_alone = np.asarray(statusTtrain[['Request', 'Retrieval']].copy())\n",
    "diff_dev_alone = np.asarray(statusDtrain[['Request', 'Retrieval']].copy())\n",
    "train_model = lr.fit(diff_alone, train_labels)\n",
    "dev_alone_labels = train_model.predict(diff_dev_alone)\n",
    "alone_score = train_model.score(diff_dev_alone, dev_labels)\n",
    "alone_F1score = metrics.f1_score(dev_alone_labels, dev_labels)\n",
    "print(\"For model with Request/Retrieval/Request-Retrieval Difference only\")\n",
    "print(\"Accuracy:\", alone_score)\n",
    "print(\"F1 score:\", alone_F1score)\n",
    "\n",
    "# Trial 2:  Z-scores for Request / Retrieval \n",
    "zdiff_train = statusTtrain[['Request Z-score','Retrieval Z-score']]\n",
    "zdiff_dev = statusDtrain[['Request Z-score','Retrieval Z-score']]\n",
    "zdiff_model = lr.fit(zdiff_train, train_labels)\n",
    "zdiff_labels = zdiff_model.predict(zdiff_dev)\n",
    "zdiff_score = zdiff_model.score(zdiff_dev, dev_labels)\n",
    "zdiff_F1score = metrics.f1_score(zdiff_labels, dev_labels)\n",
    "print(\"\\nFor model with Request / Retrieval Z-scores only :\")\n",
    "print(\"Accuracy:\", zdiff_score)\n",
    "print(\"F1 score:\", zdiff_F1score)\n",
    "\n",
    "# Trial 3:  Z-scores for Request-Retrieval \n",
    "# Create Z-scores request-retrieval\n",
    "diff_combined = np.asarray(statusTtrain[['Request-Retrieval Z-score']].copy())\n",
    "diff_dev_combined = np.asarray(statusDtrain[['Request-Retrieval Z-score']].copy())\n",
    "train_combine_model = lr.fit(diff_combined, train_labels)\n",
    "dev_combine_labels = train_combine_model.predict(diff_dev_combined)\n",
    "combine_score = train_combine_model.score(diff_dev_combined, dev_labels)\n",
    "combine_F1score = metrics.f1_score(dev_combine_labels, dev_labels)\n",
    "print(\"\\nFor model with Request-Retrieval Z-Score only\")\n",
    "print(\"Accuracy:\", combine_score)\n",
    "print(\"F1 score:\", combine_F1score)\n",
    "\n",
    "# Trial 4:  Z-scores for Request / Retrieval / Diff / Flair\n",
    "zcomb_train = statusTtrain[['Request Z-score','Retrieval Z-score','Request-Retrieval Z-score', 'requester_user_flair']]\n",
    "zcomb_train.replace(['None', 'shroom', 'PIF'], [-1, 0, 1])\n",
    "\n",
    "zcomb_dev = statusDtrain[['Request Z-score','Retrieval Z-score','Request-Retrieval Z-score', 'requester_user_flair']]\n",
    "zcomb_dev.replace(['None', 'shroom', 'PIF'], [-1, 0, 1])\n",
    "\n",
    "zcomb_model = lr.fit(zcomb_train, train_labels)\n",
    "zcomb_labels = zcomb_model.predict(zcomb_dev)\n",
    "zcomb_score = zcomb_model.score(zcomb_dev, dev_labels)\n",
    "zcomb_F1score = metrics.f1_score(zcomb_labels, dev_labels)\n",
    "print(\"\\nZ-scores for Request / Retrieval:\")\n",
    "print(\"Accuracy:\", zcomb_score)\n",
    "print(\"F1 score:\", zcomb_F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* More data pre-processing (looking for newer features too)\n",
    "* Explore PCA/LSA\n",
    "* Ideas on features\n",
    "    - Combination of words\n",
    "    - Pruning\n",
    "    - Timing (of requests)\n",
    "    - Location\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
